{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read me\n",
    "#### Always run until '[Generating label feature txt file](#Iwork)' then choose what file generator is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from scipy.misc.pilutil import imread\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import join, dirname, exists, isfile\n",
    "from os import listdir, rmdir, makedirs\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "import struct\n",
    "import xml.etree.cElementTree as et\n",
    "import xml.dom.minidom\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOOOOOOOOOOOOOOOO (You get the D later)\n",
    "imgSize = 200\n",
    "numFeatures = imgSize * imgSize * 3\n",
    "root = 'Wood_Dataset'\n",
    "# map_path = '~/Desktop/University/Imperial_College/Project/code/Wood_Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating label feature txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData_train(root):\n",
    "    print('Loading Training data')\n",
    "    path_features = join(root, 'Train')\n",
    "    images = np.zeros(shape=[5708,(200 * 200 * 3) + 1], dtype=np.int32)\n",
    "    num_images = 0\n",
    "    for i in range(1,13):\n",
    "        path = join(path_features,str(i))\n",
    "        print(path)\n",
    "        files = listdir(path)\n",
    "        for count in range(0, len(files)):\n",
    "            img_path = join(path, files[count])\n",
    "            img = imread(img_path)\n",
    "            images[count + num_images,:-1] = img.flatten()\n",
    "            images[count + num_images, -1] = i\n",
    "        print('Accessing images with label : {}'.format(str(i)))\n",
    "        num_images = num_images + len(files)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "# Save the data files into a format compatible with CNTK text reader\n",
    "def savetxt(filename, ndarray):\n",
    "    dir = dirname(filename)\n",
    "\n",
    "    if not exists(dir):\n",
    "        makedirs(dir)\n",
    "    \n",
    "    if not isfile(filename):\n",
    "        print(\"Saving\", filename )\n",
    "        with open(filename, 'w') as f:\n",
    "            labels = list(map(' '.join, np.eye(12, dtype=np.uint).astype(str)))\n",
    "            for row in ndarray:\n",
    "                row_str = row.astype(str)\n",
    "                label_str = labels[row[-1] - 1] #needs +1 as index start at 0\n",
    "                feature_str = ' '.join(row_str[:-1])\n",
    "                f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "    else:\n",
    "        print(\"File already exists\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training data\n",
      "Wood_Dataset/Train/1\n",
      "Accessing images with label : 1\n",
      "Wood_Dataset/Train/2\n",
      "Accessing images with label : 2\n",
      "Wood_Dataset/Train/3\n",
      "Accessing images with label : 3\n",
      "Wood_Dataset/Train/4\n",
      "Accessing images with label : 4\n",
      "Wood_Dataset/Train/5\n",
      "Accessing images with label : 5\n",
      "Wood_Dataset/Train/6\n",
      "Accessing images with label : 6\n",
      "Wood_Dataset/Train/7\n",
      "Accessing images with label : 7\n",
      "Wood_Dataset/Train/8\n",
      "Accessing images with label : 8\n",
      "Wood_Dataset/Train/9\n",
      "Accessing images with label : 9\n",
      "Wood_Dataset/Train/10\n",
      "Accessing images with label : 10\n",
      "Wood_Dataset/Train/11\n",
      "Accessing images with label : 11\n",
      "Wood_Dataset/Train/12\n",
      "Accessing images with label : 12\n"
     ]
    }
   ],
   "source": [
    "# train and test done seperatly to avoid memory error\n",
    "data_train = loadData_train(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-0250c17b017a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msample_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_show\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_show\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_show\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "sample_num = 4000\n",
    "data_show = data_train[sample_num,:-1].reshape(200,200,3)\n",
    "print(data_show.shape)\n",
    "plt.imshow(data_show)\n",
    "plt.show()\n",
    "print(\"Image Label: {}\".format(data_train[sample_num,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = join('data','wood')\n",
    "print('Writing train text file...')\n",
    "savetxt(join(data_dir, 'Train-Wood-Species-cntk.txt'), data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData_test(root):\n",
    "    print('Loading Test Data')\n",
    "    path_features = join(root, 'Test')\n",
    "    files = listdir(path_features)\n",
    "    images = np.zeros(shape=[len(files),(200 * 200 * 3) + 1], dtype=np.int32)\n",
    "    for count in range(0, len(files)):\n",
    "        lbl = (files[count].split('_'))[1].split('.')[0]\n",
    "        img_path = join(path_features, files[count])\n",
    "        img = imread(img_path)\n",
    "        images[count,:-1] = img.flatten()\n",
    "        images[count , -1] = lbl\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test done seperatly to avoid memory error\n",
    "data_test = loadData_test(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving test data\n",
    "print('Writing test text file ...')\n",
    "savetxt(join(data_dir, 'Test-Wood-Species-cntk.txt'), data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating label image map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMap(Train, filename):\n",
    "    print('Getting {} data'.format(('train' if Train else 'test')))\n",
    "    dir = dirname(filename)\n",
    "    with open(filename, 'w') as f:\n",
    "        if not exists(dir):\n",
    "            makedirs(dir)\n",
    "        if Train:\n",
    "            path = join(root, 'Train')\n",
    "            for i in range(1, 13):\n",
    "                image_path = join(path, str(i))\n",
    "                print('Accessing {}'.format(image_path))\n",
    "                file_list = listdir(image_path)\n",
    "                for file in file_list:\n",
    "                    f.write(\"%s\\t%d\\n\" % (join(image_path, file), i - 1))\n",
    "        else:\n",
    "            image_path = join(root, 'Test')\n",
    "            print('Accessing {}'.format(image_path))\n",
    "            file_list = listdir(image_path)\n",
    "            for file in file_list:\n",
    "                    lbl = (file.split('_'))[1].split('.')[0]\n",
    "                    f.write(\"%s\\t%d\\n\" % (join(image_path, file), int(lbl)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting train data\n",
      "Accessing Wood_Dataset/Train/1\n",
      "Accessing Wood_Dataset/Train/2\n",
      "Accessing Wood_Dataset/Train/3\n",
      "Accessing Wood_Dataset/Train/4\n",
      "Accessing Wood_Dataset/Train/5\n",
      "Accessing Wood_Dataset/Train/6\n",
      "Accessing Wood_Dataset/Train/7\n",
      "Accessing Wood_Dataset/Train/8\n",
      "Accessing Wood_Dataset/Train/9\n",
      "Accessing Wood_Dataset/Train/10\n",
      "Accessing Wood_Dataset/Train/11\n",
      "Accessing Wood_Dataset/Train/12\n",
      "Getting test data\n",
      "Accessing Wood_Dataset/Test\n"
     ]
    }
   ],
   "source": [
    "#Training map generation\n",
    "createMap(True, 'data/wood/Train-Wood-Species-Map.txt')\n",
    "#Testing map generation\n",
    "createMap(False, 'data/wood/Test-Wood-Species-Map.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating mean XML mean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMean(fname, data):\n",
    "    print('Saving XML file')\n",
    "    root = et.Element('opencv_storage')\n",
    "    et.SubElement(root, 'Channel').text = '3'\n",
    "    et.SubElement(root, 'Row').text = str(imgSize)\n",
    "    et.SubElement(root, 'Col').text = str(imgSize)\n",
    "    meanImg = et.SubElement(root, 'MeanImg', type_id='opencv-matrix')\n",
    "    et.SubElement(meanImg, 'rows').text = '1'\n",
    "    et.SubElement(meanImg, 'cols').text = str(imgSize * imgSize * 3)\n",
    "    et.SubElement(meanImg, 'dt').text = 'f'\n",
    "    et.SubElement(meanImg, 'data').text = ' '.join(['%e\\n' % n for n in np.reshape(data, (imgSize * imgSize * 3))])\n",
    "\n",
    "    tree = et.ElementTree(root)\n",
    "    tree.write(fname)\n",
    "    x = xml.dom.minidom.parse(fname)\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write(x.toprettyxml(indent = '  '))\n",
    "    print('Done!')    \n",
    "        \n",
    "def saveTrainMean():\n",
    "    print('Loading Training data')\n",
    "    path_features = join(root, 'Train')\n",
    "    images = np.zeros(shape=[5708,(200 * 200 * 3)], dtype=np.int32)\n",
    "    num_images = 0\n",
    "    for i in range(1,13):\n",
    "        path = join(path_features,str(i))\n",
    "        print(path)\n",
    "        files = listdir(path)\n",
    "        for count in range(0, len(files)):\n",
    "            img_path = join(path, files[count])\n",
    "            img = imread(img_path)\n",
    "            images[count + num_images,:] = img.flatten()\n",
    "        print('Accessing images with label : {}'.format(str(i)))\n",
    "        num_images = num_images + len(files)\n",
    "    images = (np.sum(images, axis=0))/5708\n",
    "    saveMean('data/wood/Wood-Data-Mean.xml',images)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training data\n",
      "Wood_Dataset/Train/1\n",
      "Accessing images with label : 1\n",
      "Wood_Dataset/Train/2\n",
      "Accessing images with label : 2\n",
      "Wood_Dataset/Train/3\n",
      "Accessing images with label : 3\n",
      "Wood_Dataset/Train/4\n",
      "Accessing images with label : 4\n",
      "Wood_Dataset/Train/5\n",
      "Accessing images with label : 5\n",
      "Wood_Dataset/Train/6\n",
      "Accessing images with label : 6\n",
      "Wood_Dataset/Train/7\n",
      "Accessing images with label : 7\n",
      "Wood_Dataset/Train/8\n",
      "Accessing images with label : 8\n",
      "Wood_Dataset/Train/9\n",
      "Accessing images with label : 9\n",
      "Wood_Dataset/Train/10\n",
      "Accessing images with label : 10\n",
      "Wood_Dataset/Train/11\n",
      "Accessing images with label : 11\n",
      "Wood_Dataset/Train/12\n",
      "Accessing images with label : 12\n",
      "Saving XML file\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Run mean calculator and xml saver\n",
    "saveTrainMean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
