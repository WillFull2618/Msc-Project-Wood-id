{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1>CNN model for wood species identification</h1></b>\n",
    "### 3 models can be used:\n",
    "##### - A basic testing model to check overall functionality of system\n",
    "##### - ResNET\n",
    "##### - VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.5/site-packages/cntk/cntk_py_init.py:56: UserWarning: Unsupported Linux distribution (ubuntu-18.04). CNTK supports Ubuntu 16.04 and above, only.\n",
      "  warnings.warn('Unsupported Linux distribution (%s-%s). CNTK supports Ubuntu 16.04 and above, only.' % (__my_distro__, __my_distro_ver__))\n",
      "/home/william/anaconda3/lib/python3.5/site-packages/cntk/cntk_py_init.py:98: UserWarning: \n",
      "\n",
      "################################################ Missing optional dependency (GPU-Specific) ################################################\n",
      "   CNTK may crash if the component that depends on those dependencies is loaded.\n",
      "   Visit https://docs.microsoft.com/en-us/cognitive-toolkit/Setup-Linux-Python#optional-gpu-specific-packages for more information.\n",
      "############################################################################################################################################\n",
      "If you intend to use CNTK without GPU support, you can ignore the (likely) GPU-specific warning!\n",
      "############################################################################################################################################\n",
      "\n",
      "  warnings.warn(WARNING_MSG_GPU_ONLY % ('GPU-Specific', 'https://docs.microsoft.com/en-us/cognitive-toolkit/Setup-Linux-Python#optional-gpu-specific-packages'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.5/site-packages/cntk/__init__.py\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "try:\n",
    "    from urllib.request import urlopen \n",
    "except ImportError: \n",
    "    from urllib import urlopen\n",
    "\n",
    "from cntk import load_model\n",
    "% matplotlib inline\n",
    "import cntk as C\n",
    "import cntk.io.transforms as xforms\n",
    "print(C.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheking if CPU or GPU best for training should be CPU here\n",
    "if 'TEST_DEVICE' in os.environ:\n",
    "    if os.environ['TEST_DEVICE'] == 'cpu':\n",
    "        C.device.try_set_default_device(C.device.cpu())\n",
    "    else:\n",
    "        C.device.try_set_default_device(C.device.gpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1>Reading data files: </h1></b>\n",
    "##### - XML mean file\n",
    "##### - Data map for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading input data\n",
    "envvar = 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY'\n",
    "def is_test(): return envvar in os.environ\n",
    "\n",
    "data_path = os.path.join('data','wood')\n",
    "\n",
    "# model dimensions\n",
    "image_height = 200\n",
    "image_width = 200\n",
    "num_channels = 3\n",
    "num_classes = 12\n",
    "\n",
    "#defining data readers for training and evaluation\n",
    "\n",
    "def create_reader(map_file, mean_file, train):\n",
    "    print('Reading map file: {}'.format(map_file))\n",
    "    print('Reading mean file: {}'.format(mean_file))\n",
    "    \n",
    "    transforms = []\n",
    "    \n",
    "    if train:\n",
    "        transforms += [\n",
    "            xforms.crop(crop_type='randomside', side_ratio=0.8) \n",
    "        ]\n",
    "    transforms += [\n",
    "        xforms.scale(width=image_width, height=image_height, channels=num_channels, interpolations='linear'),\n",
    "        xforms.mean(mean_file)\n",
    "    ]\n",
    "    \n",
    "    #deserializer\n",
    "    return C.io.MinibatchSource(C.io.ImageDeserializer(map_file, C.io.StreamDefs(\n",
    "        features = C.io.StreamDef(field='image', transforms=transforms), # first column in map file is referred to as 'image'\n",
    "        labels   = C.io.StreamDef(field='label', shape=num_classes)      # and second as 'label'\n",
    "    )))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading map file: data/wood/Train-Wood-Species-Map.txt\n",
      "Reading mean file: data/wood/Wood-Data-Mean.xml\n",
      "Reading map file: data/wood/Test-Wood-Species-Map.txt\n",
      "Reading mean file: data/wood/Wood-Data-Mean.xml\n"
     ]
    }
   ],
   "source": [
    "# Create  train and test data readers\n",
    "reader_train = create_reader(os.path.join(data_path, 'Train-Wood-Species-Map.txt'), \n",
    "                             os.path.join(data_path, 'Wood-Data-Mean.xml'), True)\n",
    "reader_test  = create_reader(os.path.join(data_path, 'Test-Wood-Species-Map.txt'), \n",
    "                             os.path.join(data_path, 'Wood-Data-Mean.xml'), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1> Models</h1></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model (used for testing overall system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model used here to test functionality of overall system use for testing faster training \n",
    "def create_basic_model(input, out_dims):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        net = C.layers.Convolution((5,5), 1, pad=True)(input)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.MaxPooling((3,3), strides=(2,2))(net)\n",
    "    \n",
    "        net = C.layers.Dense(5)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Dense(out_dims, activation=C.softmax)(net)\n",
    "    \n",
    "    return net       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG inspired model with dropout and batch normalisation\n",
    "def create_VGG1_model(input, out_dims):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        net = C.layers.Convolution((3,3), 32, pad=True)(input)\n",
    "        net = C.layers.Convolution((3,3), 32, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 64, pad=True)(net)\n",
    "        net = C.layers.Convolution((3,3), 64, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 128, pad=True)(net)\n",
    "        net = C.layers.Convolution((3,3), 128, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 256, pad=True)(net)\n",
    "        net = C.layers.Convolution((3,3), 256, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 512, pad=True)(net)\n",
    "        net = C.layers.Convolution((3,3), 512, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Dense(2048)(net)\n",
    "        net = C.layers.Dropout(0.3)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Dense(2048)(net)\n",
    "        net = C.layers.Dropout(0.3)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Dense(out_dims, activation=C.softmax)(net)\n",
    "    \n",
    "    return net      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG inspired model with dropout and batch normalisation\n",
    "def create_VGG2_model(input, out_dims):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        net = C.layers.Convolution((3,3), 32, pad=True)(input)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Convolution((3,3), 32, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 64, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Convolution((3,3), 64, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 128, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Convolution((3,3), 128, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 256, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Convolution((3,3), 256, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Convolution((3,3), 512, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Convolution((3,3), 512, pad=True)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.MaxPooling((2,2), strides=(2,2))(net)\n",
    "        \n",
    "        net = C.layers.Dense(2048)(net)\n",
    "        net = C.layers.Dropout(0.3)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Dense(2048)(net)\n",
    "        net = C.layers.Dropout(0.3)(net)\n",
    "        net = C.layers.BatchNormalization(map_rank=1)(net)\n",
    "        net = C.layers.Dense(out_dims, activation=C.softmax)(net)\n",
    "    \n",
    "    return net   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1> Training (with basic test result)</h1></b>\n",
    "\n",
    "##### Skip to [here](#trained_model), to skip training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing network\n",
    "def train_and_test(reader_train, reader_test, max_epochs, model_func, saving_rate=5):\n",
    "    \n",
    "    \n",
    "    # saving trainer location\n",
    "    chk = 'checkpoints/VGG/test_run_2/trainer_VGG_.dnn'\n",
    "    run_number = 0 # multiple of 5\n",
    "    # input containers for labels and features of data\\\n",
    "    input_var = C.input_variable((num_channels, image_height, image_width))\n",
    "    label_var = C.input_variable(num_classes)\n",
    "    \n",
    "    # Normalize the input data (improves performance)\n",
    "    feature_scale = 1.0 / 256\n",
    "    input_var_norm = C.element_times(feature_scale, input_var)\n",
    "    \n",
    "    # apply model to input\n",
    "    z = model_func(input_var_norm, out_dims=12)\n",
    "    \n",
    "    #\n",
    "    # Training section\n",
    "    #\n",
    "    \n",
    "    # defining loss function and metric for training\n",
    "    \n",
    "    # loss and metric\n",
    "    ce = C.cross_entropy_with_softmax(z, label_var)\n",
    "    pe = C.classification_error(z, label_var)\n",
    "    \n",
    "    # training configuration\n",
    "    epoch_size = 5708 # number of testing samples\n",
    "    minibatch_size = 64 # may need adjusting based on system memory\n",
    "    \n",
    "    # training parameters\n",
    "    lr_per_minibatch = C.learning_parameter_schedule([0.1] * 30 + [0.05] * 20 + [0.01],\n",
    "                                                    epoch_size=epoch_size)\n",
    "    momentums        = C.momentum_schedule(0.9, minibatch_size = minibatch_size)\n",
    "    l2_reg_weight   = 0.001\n",
    "    \n",
    "    #trainer object\n",
    "    learner = C.momentum_sgd(z.parameters,\n",
    "                            lr = lr_per_minibatch,\n",
    "                            momentum = momentums,\n",
    "                            l2_regularization_weight = l2_reg_weight)\n",
    "    progress_printer = C.logging.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n",
    "    \n",
    "    #initialize trainer object \n",
    "    trainer = C.Trainer(z, (ce,pe), [learner], [progress_printer])\n",
    "    \n",
    "    # restore from checkpoint \n",
    "    if os.path.exists(chk):\n",
    "        print('Restoring from checkpoint')\n",
    "        mb_source_state = trainer.restore_from_checkpoint(chk)\n",
    "        reader_train.restore_from_checkpoint(mb_source_state)\n",
    "    else:\n",
    "        print('Random Init')\n",
    "        \n",
    "    \n",
    "            \n",
    "    # define mapping from reader streams to network inputs\n",
    "    input_map = {\n",
    "        input_var: reader_train.streams.features,\n",
    "        label_var: reader_train.streams.labels\n",
    "    }\n",
    "    \n",
    "    C.logging.log_number_of_parameters(z) ; print()\n",
    "    \n",
    "    # perform model training\n",
    "    batch_index = 0 \n",
    "    plot_data = {'batchindex':[], 'loss':[], 'error':[]}\n",
    "    for epoch in range(max_epochs): # loop over epochs\n",
    "        sample_count = 0\n",
    "        \n",
    "        while sample_count < epoch_size: # loop over minibatches in the epoch\n",
    "            data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count),\n",
    "                                              input_map=input_map) # fetch the gooood minibacth\n",
    "            trainer.train_minibatch(data)                          # updat model with da good minibatch\n",
    "            \n",
    "            sample_count += data[label_var].num_samples            # count number of samples processed\n",
    "            \n",
    "            # display results\n",
    "            plot_data['batchindex'].append(batch_index)\n",
    "            plot_data['loss'].append(trainer.previous_minibatch_loss_average)\n",
    "            plot_data['error'].append(trainer.previous_minibatch_evaluation_average)\n",
    "            \n",
    "            batch_index += 1\n",
    "        # checkpoint saving\n",
    "        if (epoch+1) % saving_rate == 0:\n",
    "            mb_source_chk = reader_train.get_checkpoint_state()\n",
    "            trainer.save_checkpoint('checkpoints/VGG/test_run_2/trainer_VGG_{}.dnn'.format(str(epoch+run_number+1)), mb_source_chk)\n",
    "            z.save('model/VGG/test_run_2/VGG_0.1_{}.model'.format(str(epoch+run_number+1)))\n",
    "            \n",
    "            \n",
    "        trainer.summarize_training_progress()\n",
    "    #\n",
    "    # Evaluation action\n",
    "    #\n",
    "    epoch_size     = 2836\n",
    "    minibatch_size = 32\n",
    "\n",
    "    # process minibatches and evaluate the model\n",
    "    metric_numer    = 0\n",
    "    metric_denom    = 0\n",
    "    sample_count    = 0\n",
    "    minibatch_index = 0\n",
    "\n",
    "    while sample_count < epoch_size:\n",
    "        current_minibatch = min(minibatch_size, epoch_size - sample_count)\n",
    "\n",
    "        # Fetch next test min batch.\n",
    "        data = reader_test.next_minibatch(current_minibatch, input_map=input_map)\n",
    "\n",
    "        # minibatch data to be trained with\n",
    "        metric_numer += trainer.test_minibatch(data) * current_minibatch\n",
    "        metric_denom += current_minibatch\n",
    "\n",
    "        # Keep track of the number of samples processed so far.\n",
    "        sample_count += data[label_var].num_samples\n",
    "        minibatch_index += 1\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Final Results: Minibatch[1-{}]: errs = {:0.1f}% * {}\".format(minibatch_index+1, (metric_numer*100.0)/metric_denom, metric_denom))\n",
    "    print(\"\")\n",
    "\n",
    "    # Visualize training result:\n",
    "    window_width = 8\n",
    "    loss_cumsum  = np.cumsum(np.insert(plot_data['loss'], 0, 0))\n",
    "    error_cumsum = np.cumsum(np.insert(plot_data['error'], 0, 0))\n",
    "    \n",
    "    # Moving Average\n",
    "    plot_data['batchindex'] = np.insert(plot_data['batchindex'], 0, 0)[window_width:]\n",
    "    plot_data['avg_loss']   = (loss_cumsum[window_width:] - loss_cumsum[:-window_width]) / window_width\n",
    "    plot_data['avg_error']  = (error_cumsum[window_width:] - error_cumsum[:-window_width]) / window_width\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(plot_data[\"batchindex\"], plot_data[\"avg_loss\"], 'b--')\n",
    "    plt.xlabel('Minibatch number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Minibatch run vs. Training loss ')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(plot_data[\"batchindex\"], plot_data[\"avg_error\"], 'r--')\n",
    "    plt.xlabel('Minibatch number')\n",
    "    plt.ylabel('Label Prediction Error')\n",
    "    plt.title('Minibatch run vs. Label Prediction Error ')\n",
    "    plt.show()\n",
    "    \n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic model (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_basic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-94b702aceacc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                      \u001b[0mreader_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                      \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[1;31m# change number of epochs here\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                      model_func=create_basic_model)\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_basic_model' is not defined"
     ]
    }
   ],
   "source": [
    "# train basic model from random init\n",
    "pred_basic_model = train_and_test(reader_train,\n",
    "                     reader_test,\n",
    "                     max_epochs=5,    # change number of epochs here\n",
    "                     model_func=create_basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Init\n",
      "Training 46696108 parameters in 50 parameter tensors.\n",
      "\n",
      "Learning rate per minibatch: 0.1\n",
      "Momentum per 64 samples: 0.9\n"
     ]
    }
   ],
   "source": [
    "# train VGG model\n",
    "VGG_model = train_and_test(reader_train,\n",
    "                     reader_test,\n",
    "                     max_epochs=1,            # change number of epochs here\n",
    "                     model_func=create_VGG2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h1>Testing models</h1></b>\n",
    "##### Need to add better output option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of test data returns list of filenames and idx\n",
    "def read_test_img(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        filenames_idx = list()\n",
    "        for line in range(len(lines)):\n",
    "            filenames_idx.append(lines[line].split('\\t'))    \n",
    "        f.close()\n",
    "        return filenames_idx\n",
    "    \n",
    "# create list of features or labels\n",
    "def image_lbl_list(mapfile, features):\n",
    "    \n",
    "    if features:\n",
    "        images = list()\n",
    "        for img_num in range(len(mapfile)):\n",
    "            img = np.asarray(Image.open(mapfile[img_num][0]), np.float32)\n",
    "            img = np.ascontiguousarray(np.transpose(img, (2, 0, 1)))\n",
    "            images.append(img)\n",
    "        return images\n",
    "    else:\n",
    "        labels = np.zeros((len(mapfile),1))\n",
    "        for lbl_num in range(len(mapfile)):\n",
    "            labels[lbl_num] = mapfile[lbl_num][1]\n",
    "        return np.float32(labels)\n",
    "\n",
    "# test model on single image\n",
    "def eval_single_image(model, image_path):\n",
    "    try:\n",
    "        #print('Opening: {}'.format(image_path))\n",
    "        img = Image.open(image_path)\n",
    "        img = np.asarray(img, np.float32) - 150\n",
    "        image_data = img[..., [2, 1, 0]]\n",
    "        image_data = np.ascontiguousarray(np.rollaxis(image_data, 2))\n",
    "        output = np.squeeze(model.eval({model.arguments[0]:[image_data]}))\n",
    "\n",
    "        # return probabilities\n",
    "\n",
    "        return output\n",
    "\n",
    "    except FileNotFoundError:\n",
    "            print('Could not open (skipping file): {}'.format(image_path))\n",
    "            return['None'] \n",
    "        \n",
    "# eval all the test images     \n",
    "def eval_test_images(images_lbls, model):\n",
    "    num_correct = 0\n",
    "    for i in range(len(images_lbls)):\n",
    "        image_path = images_lbls[i][0]\n",
    "        lbl = int(images_lbls[i][1])\n",
    "        pred = eval_single_image(model, image_path)\n",
    "        pred = np.argmax(pred)\n",
    "        if pred == lbl:\n",
    "            num_correct = num_correct + 1\n",
    "            \n",
    "        if i%500 == 0 and i != 0:\n",
    "            print('Processed 500 test images, current accuracy: {:0.2f}%'.format(100 * num_correct/i))\n",
    "    print('Total Accuracy: {:0.2f}%'.format(100 * num_correct / len(images_lbls)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic model (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labe: 0\n",
      "True label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Single image with basic model\n",
    "image_num = 7\n",
    "model = load_model('model/VGG/VGG_0.01_15.model')\n",
    "file_path_test = 'data/wood/Test-Wood-Species-Map.txt'\n",
    "filenames_lbls = read_test_img(file_path_test)\n",
    "result = eval_single_image(model, filenames_lbls[image_num][0])\n",
    "predicted_label = np.argmax(result)\n",
    "print('predicted labe: {}'.format(predicted_label))\n",
    "print('True label: {}'.format(filenames_lbls[image_num][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 test images, current accuracy: 33.60%\n",
      "Processed 500 test images, current accuracy: 37.20%\n",
      "Processed 500 test images, current accuracy: 34.33%\n",
      "Processed 500 test images, current accuracy: 33.80%\n",
      "Processed 500 test images, current accuracy: 33.76%\n",
      "Total Accuracy: 33.82%\n"
     ]
    }
   ],
   "source": [
    "# Test all images basic model\n",
    "\n",
    "model = load_model('model/VGG/VGG_0.01_15.model')\n",
    "test_file_path = 'data/wood/Test-Wood-Species-Map.txt'\n",
    "filenames_lbls = read_test_img(test_file_path)\n",
    "eval_test_images(filenames_lbls,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  VGG model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Single image with basic model\n",
    "image_num = 5\n",
    "pred_basic_model = load_model('model/VGG/VGG_0.01_5.model')\n",
    "file_path_test = 'data/wood/Test-Wood-Species-Map.txt'\n",
    "filenames_lbls = read_test_img(file_path_test)\n",
    "result = eval_single_image(VGG_model, filenames_lbls[image_num][0])\n",
    "predicted_label = np.argmax(result)\n",
    "print('predicted labe: {}'.format(predicted_label))\n",
    "print('True label: {}'.format(filenames_lbls[image_num][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all images basic model\n",
    "\n",
    "model = load_model('models/VGG_model.model')\n",
    "test_file_path = 'data/wood/Test-Wood-Species-Map.txt'\n",
    "filenames_lbls = read_test_img(test_file_path)\n",
    "eval_test_images(filenames_lbls,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Single image with basic model\n",
    "image_num = 5\n",
    "pred_basic_model = load_model('models/resnet_model.model')\n",
    "file_path_test = 'data/wood/Test-Wood-Species-Map.txt'\n",
    "filenames_lbls = read_test_img(file_path_test)\n",
    "result = eval_single_image(pred_basic_model, filenames_lbls[image_num][0])\n",
    "predicted_label = np.argmax(result)\n",
    "print('predicted labe: {}'.format(predicted_label))\n",
    "print('True label: {}'.format(filenames_lbls[image_num][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all images basic model\n",
    "\n",
    "model = load_model('models/resnet_model.model')\n",
    "test_file_path = 'data/wood/Test-Wood-Species-Map.txt'\n",
    "filenames_lbls = read_test_img(test_file_path)\n",
    "eval_test_images(filenames_lbls,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
